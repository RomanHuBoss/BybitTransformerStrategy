import pandas as pd
import numpy as np
import joblib
import logging
import os
from sklearn.preprocessing import StandardScaler
from config import CFG
from feature_engineering import FeatureEngineer

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# Direction Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐ° (Ð¾ÑÑ‚Ð°Ð»Ð°ÑÑŒ Ð¿Ñ€ÐµÐ¶Ð½ÐµÐ¹)
def generate_direction_labels(df, threshold, lookahead):
    closes = df["close"].values
    future_closes = np.roll(closes, -lookahead)
    changes = (future_closes - closes) / closes
    changes[-lookahead:] = 0  # Ñ…Ð²Ð¾ÑÑ‚

    labels = np.full(len(df), 1)
    labels[changes > threshold] = 2
    labels[changes < -threshold] = 0
    return labels.tolist()


# Ð£ÑÐºÐ¾Ñ€ÐµÐ½Ð½Ð°Ñ Amplitude Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐ°
def generate_amplitude_labels(df, lookahead):
    highs = df['high'].values
    lows = df['low'].values
    closes = df['close'].values

    n = len(df)
    amp_up_p10, amp_up_p90 = [], []
    amp_down_p10, amp_down_p90 = [], []

    for i in range(n):
        window_highs = highs[i+1:i+1+lookahead]
        window_lows = lows[i+1:i+1+lookahead]

        if len(window_highs) < lookahead:
            amp_up_p10.append(0)
            amp_up_p90.append(0)
            amp_down_p10.append(0)
            amp_down_p90.append(0)
            continue

        up_moves = (window_highs - closes[i]) / closes[i]
        down_moves = (closes[i] - window_lows) / closes[i]

        amp_up_p10.append(np.quantile(up_moves, 0.1))
        amp_up_p90.append(np.quantile(up_moves, 0.9))
        amp_down_p10.append(np.quantile(down_moves, 0.1))
        amp_down_p90.append(np.quantile(down_moves, 0.9))

    return pd.DataFrame({
        'amp_up_p10': amp_up_p10,
        'amp_up_p90': amp_up_p90,
        'amp_down_p10': amp_down_p10,
        'amp_down_p90': amp_down_p90
    })


# HitOrder Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐ° (ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð½Ð°Ñ Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐµÐ½Ð½Ð°Ñ)
def generate_hitorder_labels(df, sl_list, rr_list, lookahead):
    result = {}

    highs = df["high"].values
    lows = df["low"].values
    closes = df["close"].values
    n = len(df)

    for sl in sl_list:
        for rr in rr_list:
            column_name = f"hit_SL{sl}_RR{rr}"
            labels = np.zeros(n, dtype=int)

            tp_prices = closes * (1 + rr * sl)
            sl_prices = closes * (1 - sl)

            for i in range(n):
                start_idx = i + 1
                end_idx = i + 1 + lookahead

                if end_idx >= n:
                    labels[i] = 0
                    continue

                high_window = highs[start_idx:end_idx]
                low_window = lows[start_idx:end_idx]

                hit_tp = high_window >= tp_prices[i]
                hit_sl = low_window <= sl_prices[i]

                first_tp = np.argmax(hit_tp) if np.any(hit_tp) else lookahead + 1
                first_sl = np.argmax(hit_sl) if np.any(hit_sl) else lookahead + 1

                labels[i] = 1 if first_tp < first_sl else 0

            result[column_name] = labels

    for col, values in result.items():
        df[col] = values

    return df


def main():
    logging.info("ðŸš€ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ...")
    df = pd.read_csv(CFG.paths.train_csv)
    logging.info(f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(df)} ÑÑ‚Ñ€Ð¾Ðº")

    logging.info("ðŸ§ª Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸...")
    fe = FeatureEngineer(feature_columns=None)
    df_features = fe.generate_features(df, fit=True)
    logging.info(f"âœ… Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²: {df_features.shape[1]}")

    df = df.tail(len(df_features)).reset_index(drop=True)
    df_features = df_features.reset_index(drop=True)

    logging.info("ðŸ· Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Direction Ð¼ÐµÑ‚ÐºÐ¸...")
    df_features['direction_label'] = generate_direction_labels(
        df,
        threshold=CFG.label_generation.direction_threshold,
        lookahead=CFG.label_generation.direction_lookahead
    )

    logging.info("ðŸ“ˆ Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Amplitude Ð¼ÐµÑ‚ÐºÐ¸ (ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð½Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ)...")
    amp_labels = generate_amplitude_labels(
        df,
        lookahead=CFG.label_generation.amplitude_lookahead
    )
    df_features = pd.concat([df_features, amp_labels], axis=1)

    logging.info("ðŸŽ¯ Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ HitOrder Ð¼ÐµÑ‚ÐºÐ¸ (ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð½Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ)...")
    df_features = generate_hitorder_labels(
        df,
        sl_list=CFG.label_generation.hitorder_sl_list,
        rr_list=CFG.label_generation.hitorder_rr_list,
        lookahead=CFG.label_generation.hitorder_lookahead
    )

    df_features.dropna(inplace=True)
    df_features.reset_index(drop=True, inplace=True)
    logging.info(f"ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚: {len(df_features)} ÑÑ‚Ñ€Ð¾Ðº")
    df_features.to_csv(CFG.paths.train_features_csv, index=False)

    logging.info("âš™ï¸ ÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼ scaler Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸...")

    non_feature_cols = [
        'open_time', 'close_time', 'timestamp', 'date', 'symbol',
        'quote_volume', 'count', 'taker_buy_volume', 'taker_buy_quote_volume', 'ignore'
    ]

    non_label_cols = ['direction_label'] + [
        col for col in df_features.columns if col.startswith("amp_") or col.startswith("hit_SL")
    ]

    feature_cols = [
        col for col in df_features.columns
        if col not in (non_feature_cols + non_label_cols)
    ]

    scaler = StandardScaler()
    scaler.fit(df_features[feature_cols])

    joblib.dump(scaler, CFG.paths.scaler_path)
    joblib.dump(feature_cols, CFG.paths.feature_columns_path)

    logging.info("âœ… Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸ scaler Ð¸ feature_columns.")

if __name__ == "__main__":
    main()
