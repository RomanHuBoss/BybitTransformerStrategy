import pandas as pd
import numpy as np
import logging
import joblib
from sklearn.preprocessing import StandardScaler
from config import CFG
from feature_engineering import FeatureEngineer

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è direction-–º–µ—Ç–æ–∫ (3 –∫–ª–∞—Å—Å–∞: –ø–∞–¥–µ–Ω–∏–µ, –±–æ–∫–æ–≤–∏–∫, —Ä–æ—Å—Ç)
def generate_direction_labels(df, threshold, lookahead):
    labels = []
    for i in range(len(df)):
        if i + lookahead >= len(df):
            labels.append(1)  # –Ω–µ—Ç –±—É–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö ‚Üí —Å—á–∏—Ç–∞–µ–º –±–æ–∫–æ–≤–∏–∫
            continue

        future_close = df.iloc[i + lookahead]["close"]
        change = (future_close - df.iloc[i]["close"]) / df.iloc[i]["close"]

        if change > threshold:
            labels.append(2)  # —Ä–æ—Å—Ç
        elif change < -threshold:
            labels.append(0)  # –ø–∞–¥–µ–Ω–∏–µ
        else:
            labels.append(1)  # –±–æ–∫–æ–≤–∏–∫
    return labels

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è amplitude-–º–µ—Ç–æ–∫ (–∞–º–ø–ª–∏—Ç—É–¥–Ω—ã–µ –∫–≤–∞–Ω—Ç–∏–ª–∏ –±—É–¥—É—â–∏—Ö –¥–≤–∏–∂–µ–Ω–∏–π)
def generate_amplitude_labels(df, lookahead):
    up_p10, up_p90, down_p10, down_p90 = [], [], [], []

    for i in range(len(df)):
        if i + lookahead >= len(df):
            # –ù–µ—Ç –±—É–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö ‚Äî —Å—á–∏—Ç–∞–µ–º –∫–∞–∫ –∏–¥–µ–∞–ª—å–Ω—ã–π –±–æ–∫–æ–≤–∏–∫ (–Ω—É–ª–µ–≤–∞—è –∞–º–ø–ª–∏—Ç—É–¥–∞)
            up_p10.append(0)
            up_p90.append(0)
            down_p10.append(0)
            down_p90.append(0)
            continue

        window = df.iloc[i + 1: i + lookahead + 1]
        price = df.iloc[i]["close"]

        up = (window["high"] - price) / price
        down = (price - window["low"]) / price

        up_p10.append(up.quantile(0.1))
        up_p90.append(up.quantile(0.9))
        down_p10.append(down.quantile(0.1))
        down_p90.append(down.quantile(0.9))

    return pd.DataFrame({
        "amp_up_p10": up_p10,
        "amp_up_p90": up_p90,
        "amp_down_p10": down_p10,
        "amp_down_p90": down_p90
    })

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è hitorder-–º–µ—Ç–æ–∫ (—Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–µ TP/SL –ø–æ –ø—Ä–æ—Ñ–∏–ª—è–º)
def generate_hitorder_labels(df, sl_list, rr_list, lookahead):
    result = {}

    for sl in sl_list:
        for rr in rr_list:
            column_name = f"hit_SL{sl}_RR{rr}"
            labels = []

            for i in range(len(df)):
                start_idx = i + 1
                end_idx = i + 1 + lookahead

                if end_idx >= len(df):
                    labels.append(0)  # –Ω–µ—Ç –±—É–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö ‚Äî —Å—á–∏—Ç–∞–µ–º –∫–∞–∫ SL
                    continue

                entry_price = df.iloc[i]['close']
                tp_price = entry_price * (1 + rr * sl)
                sl_price = entry_price * (1 - sl)

                window = df.iloc[start_idx:end_idx]
                hit_label = None

                for _, row in window.iterrows():
                    high = row['high']
                    low = row['low']

                    if high >= tp_price and low <= sl_price:
                        hit_label = 0  # –æ–±–∞ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã ‚Äî SL
                        break
                    elif high >= tp_price:
                        hit_label = 1  # TP
                        break
                    elif low <= sl_price:
                        hit_label = 0  # SL
                        break

                if hit_label is None:
                    labels.append(0)  # –Ω–∏—á–µ–≥–æ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ ‚Äî —Å—á–∏—Ç–∞–µ–º SL
                else:
                    labels.append(hit_label)

            result[column_name] = labels

    for col, values in result.items():
        df[col] = values

    return df

def main():
    logging.info("üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
    df = pd.read_csv(CFG.paths.train_csv)
    logging.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫")

    logging.info("üß™ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏...")
    fe = FeatureEngineer()
    df_features = fe.generate_features(df, fit=True)
    logging.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {df_features.shape[1]}")

    # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –¥–ª–∏–Ω–æ–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ feature engineering
    df = df.tail(len(df_features)).reset_index(drop=True)
    df_features = df_features.reset_index(drop=True)

    logging.info("üè∑ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Direction –º–µ—Ç–∫–∏...")
    df_features['direction_label'] = generate_direction_labels(
        df,
        threshold=CFG.label_generation.direction_threshold,
        lookahead=CFG.label_generation.direction_lookahead
    )

    logging.info("üìà –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Amplitude –º–µ—Ç–∫–∏...")
    amp_labels = generate_amplitude_labels(
        df,
        lookahead=CFG.label_generation.amplitude_lookahead
    )
    df_features = pd.concat([df_features, amp_labels], axis=1)

    logging.info("üéØ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HitOrder –º–µ—Ç–∫–∏...")
    df_features = generate_hitorder_labels(
        df,
        sl_list=CFG.label_generation.hitorder_sl_list,
        rr_list=CFG.label_generation.hitorder_rr_list,
        lookahead=CFG.label_generation.hitorder_lookahead
    )

    # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ –≤ —Å–∞–º–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö (—Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏ –∏—Ö –±—ã—Ç—å –Ω–µ –¥–æ–ª–∂–Ω–æ)
    df_features.dropna(inplace=True)
    df_features.reset_index(drop=True, inplace=True)

    logging.info(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {len(df_features)} —Å—Ç—Ä–æ–∫")
    df_features.to_csv(CFG.paths.train_features_csv, index=False)

    # ‚¨áÔ∏è –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô scaler –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:

    logging.info("‚öôÔ∏è –û–±—É—á–∞–µ–º scaler –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏...")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏: –≤—Å—ë –∫—Ä–æ–º–µ –ª–µ–π–±–ª–æ–≤
    feature_cols = [col for col in df_features.columns if not col.startswith("direction_label")
                     and not col.startswith("amp_")
                     and not col.startswith("hit_SL")]

    # –û–±—É—á–∞–µ–º scaler
    scaler = StandardScaler()
    scaler.fit(df_features[feature_cols])

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º scaler –∏ —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    joblib.dump(scaler, CFG.paths.scaler_path)
    pd.Series(feature_cols).to_csv(CFG.paths.feature_columns_path, index=False)

    logging.info("‚úÖ –°–æ—Ö—Ä–∞–Ω–∏–ª–∏ scaler –∏ feature_columns.")

if __name__ == "__main__":
    main()
