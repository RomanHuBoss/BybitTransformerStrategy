import logging
import pandas as pd
import numpy as np
import joblib
from config import CFG
from feature_engineering import FeatureEngineer

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# 1ï¸âƒ£ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
logging.info("Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ð³Ð¾ train_csv...")
df_raw = pd.read_csv(CFG.paths.train_csv)
logging.info(f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(df_raw)} ÑÑ‚Ñ€Ð¾Ðº Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…")

# 2ï¸âƒ£ Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
logging.info("Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²...")
engineer = FeatureEngineer()
features = engineer.generate_features(df_raw, fit=True)
joblib.dump(engineer.scaler, CFG.paths.scaler_path)
joblib.dump(engineer.feature_columns, CFG.paths.feature_columns_path)
logging.info(f"âœ… Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸: {features.shape}")

# ÐŸÑ€Ð¸Ð²ÑÐ·ÐºÐ° Ð¸Ð½Ð´ÐµÐºÑÐ¾Ð² Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð¸ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
df_clean = df_raw.loc[features.index].reset_index(drop=True)
features.reset_index(drop=True, inplace=True)

# 3ï¸âƒ£ Direction Ð¼ÐµÑ‚ÐºÐ¸ (range-based, ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð¾Ñ‚ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ ÑÐ²ÐµÑ‡Ð¸)
logging.info("Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Direction Ð¼ÐµÑ‚Ð¾Ðº (range-based)...")

lookahead = CFG.label_generation.direction_shift  # Ð»ÑƒÑ‡ÑˆÐµ Ð±Ñ‹ Ð½Ð°Ð·Ð²Ð°Ñ‚ÑŒ direction_lookahead
threshold = CFG.label_generation.direction_threshold

direction_labels = []
for idx in range(len(df_clean) - lookahead):
    current_close = df_clean.iloc[idx]['close']
    future_window = df_clean.iloc[idx : idx + lookahead]

    max_return = (future_window['high'].max() - current_close) / current_close
    min_return = (future_window['low'].min() - current_close) / current_close

    if max_return > threshold:
        label = 2  # long
    elif min_return < -threshold:
        label = 0  # short
    else:
        label = 1  # no-trade

    direction_labels.append(label)

labels_direction = np.array(direction_labels)

valid_length = len(labels_direction)
features = features.iloc[:valid_length].reset_index(drop=True)
df_clean = df_clean.iloc[:valid_length].reset_index(drop=True)

assert len(features) == len(labels_direction), "Ð Ð°ÑÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½ Ð¿Ð¾ÑÐ»Ðµ Direction!"
logging.info(f"âœ… Direction Ð¼ÐµÑ‚ÐºÐ¸ (range-based): {len(labels_direction)}")

# 4ï¸âƒ£ Amplitude Ð¼ÐµÑ‚ÐºÐ¸ (30 Ð½Ð°Ð·Ð°Ð´ Ð¸ 20 Ð²Ð¿ÐµÑ€Ñ‘Ð´)
logging.info("Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Amplitude Ð¼ÐµÑ‚Ð¾Ðº...")

past_window = CFG.feature_engineering.window_size  # 30 Ð½Ð°Ð·Ð°Ð´
future_window = CFG.label_generation.amplitude_shift  # 20 Ð²Ð¿ÐµÑ€Ñ‘Ð´

min_sl = CFG.label_generation.amplitude_min_sl
max_sl = CFG.label_generation.amplitude_max_sl
max_tp = CFG.label_generation.amplitude_max_tp

amp_labels = []
for idx in range(past_window, len(df_clean) - future_window):
    current_close = df_clean.iloc[idx]['close']
    future_win = df_clean.iloc[idx : idx + future_window]

    up_ampl = (future_win['high'] - current_close) / current_close
    down_ampl = (current_close - future_win['low']) / current_close

    down_p10 = np.clip(np.percentile(down_ampl, 10), min_sl, max_sl)
    down_p90 = np.clip(np.percentile(down_ampl, 90), min_sl, max_sl)
    up_p10 = np.clip(max(np.percentile(up_ampl, 10), 2 * down_p10), 2 * down_p10, max_tp)
    up_p90 = np.clip(max(np.percentile(up_ampl, 90), 2 * down_p90), 2 * down_p90, max_tp)

    amp_labels.append([up_p10, up_p90, down_p10, down_p90])

labels_amplitude = np.array(amp_labels)

features = features.iloc[past_window : past_window + len(labels_amplitude)].reset_index(drop=True)
df_clean = df_clean.iloc[past_window : past_window + len(labels_amplitude)].reset_index(drop=True)
labels_direction = labels_direction[past_window : past_window + len(labels_amplitude)]

assert len(features) == len(labels_amplitude) == len(labels_direction), "Ð Ð°ÑÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½ Ð¿Ð¾ÑÐ»Ðµ Amplitude!"
logging.info(f"âœ… Amplitude Ð¼ÐµÑ‚ÐºÐ¸: {len(labels_amplitude)}")

# 5ï¸âƒ£ HitOrder Ð¼ÐµÑ‚ÐºÐ¸ (Ð½Ð°ÑÑ‚Ð¾ÑÑ‰Ð¸Ð¹ supervised Ñ€ÐµÐ¶Ð¸Ð¼ â€” Ð¾Ñ‚ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ ÑÐ²ÐµÑ‡Ð¸)
logging.info("Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ HitOrder Ð¼ÐµÑ‚Ð¾Ðº...")

window = CFG.label_generation.hit_order_window
sl_min = CFG.label_generation.hit_order_sl_min
sl_max = CFG.label_generation.hit_order_sl_max
rr_min = CFG.label_generation.hit_order_rr_min
rr_max = CFG.label_generation.hit_order_rr_max

hit_labels = []
for idx in range(len(df_clean) - window):
    win = df_clean.iloc[idx : idx + window]
    close = df_clean.iloc[idx]['close']

    sl_relative = np.random.uniform(sl_min, sl_max)
    sl_level = close * (1 - sl_relative)
    rr = np.random.uniform(rr_min, rr_max)
    tp_relative = sl_relative * rr
    tp_level = close * (1 + tp_relative)

    hit = 0
    for _, row in win.iterrows():
        if row['high'] >= tp_level:
            hit = 1
            break
        elif row['low'] <= sl_level:
            hit = 0
            break
    hit_labels.append([sl_relative, tp_relative, hit])

labels_hitorder = np.array(hit_labels)

# Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ
final_len = len(labels_hitorder)
features = features.iloc[:final_len].reset_index(drop=True)
labels_direction = labels_direction[:final_len]
labels_amplitude = labels_amplitude[:final_len]

assert len(features) == len(labels_hitorder) == len(labels_amplitude) == len(labels_direction), "Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð°ÑÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½!"

# 6ï¸âƒ£ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼
features.to_csv(CFG.paths.train_features_csv, index=False)
np.save(CFG.paths.train_labels_direction, labels_direction)
np.save(CFG.paths.train_labels_amplitude, labels_amplitude)
np.save(CFG.paths.train_labels_hitorder, labels_hitorder)

logging.info(f"âœ… Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾: {len(features)} ÑÑ‚Ñ€Ð¾Ðº")
logging.info("ðŸŽ¯ ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð±Ð¾ÐµÐ²Ð¾Ð¹ FINISHED pipeline ÑÐ¾Ð±Ñ€Ð°Ð½.")
