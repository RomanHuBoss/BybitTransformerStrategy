import logging
import pandas as pd
import numpy as np
import joblib
from config import CFG
from feature_engineering import FeatureEngineer

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# 1ï¸âƒ£ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
logging.info("Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ð³Ð¾ train_csv...")
df_raw = pd.read_csv(CFG.paths.train_csv)
logging.info(f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(df_raw)} ÑÑ‚Ñ€Ð¾Ðº Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…")

# 2ï¸âƒ£ Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
logging.info("Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²...")
engineer = FeatureEngineer()
features = engineer.generate_features(df_raw, fit=True)
joblib.dump(engineer.scaler, CFG.paths.scaler_path)
joblib.dump(engineer.feature_columns, CFG.paths.feature_columns_path)
logging.info(f"âœ… Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸: {features.shape}")

# ÐŸÑ€Ð¸Ð²ÑÐ·ÐºÐ° Ð¸Ð½Ð´ÐµÐºÑÐ¾Ð² Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð¸ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
df_clean = df_raw.loc[features.index].reset_index(drop=True)
features.reset_index(drop=True, inplace=True)

# 3ï¸âƒ£ Direction Ð¼ÐµÑ‚ÐºÐ¸
logging.info("Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Direction Ð¼ÐµÑ‚Ð¾Ðº...")
lookahead = CFG.label_generation.direction_shift
threshold = CFG.label_generation.direction_threshold

future_close = df_clean['close'].shift(-lookahead)
current_close = df_clean['close']
returns = (future_close - current_close) / current_close
labels_direction = np.where(returns > threshold, 2, np.where(returns < -threshold, 0, 1))

valid_length = len(df_clean) - lookahead
features = features.iloc[:valid_length].reset_index(drop=True)
df_clean = df_clean.iloc[:valid_length].reset_index(drop=True)
labels_direction = labels_direction[:valid_length]

assert len(features) == len(labels_direction), "Ð Ð°ÑÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½ Ð¿Ð¾ÑÐ»Ðµ Direction!"
np.save(CFG.paths.train_labels_direction, labels_direction)
logging.info(f"âœ… Direction Ð¼ÐµÑ‚ÐºÐ¸: {len(labels_direction)}")

# 4ï¸âƒ£ Amplitude Ð¼ÐµÑ‚ÐºÐ¸
logging.info("Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Amplitude Ð¼ÐµÑ‚Ð¾Ðº...")
shift = CFG.label_generation.amplitude_shift
window = CFG.label_generation.quantile_window
min_sl, max_sl, max_tp = 0.005, 0.02, 0.15

amp_labels = []
for idx in range(len(df_clean) - shift - window + 1):
    win = df_clean.iloc[idx + shift: idx + shift + window]
    close = df_clean.iloc[idx]['close']
    up_ampl = (win['high'] - close) / close
    down_ampl = (close - win['low']) / close

    down_p10 = np.clip(np.percentile(down_ampl, 10), min_sl, max_sl)
    down_p90 = np.clip(np.percentile(down_ampl, 90), min_sl, max_sl)
    up_p10 = np.clip(max(np.percentile(up_ampl, 10), 2 * down_p10), 2 * down_p10, max_tp)
    up_p90 = np.clip(max(np.percentile(up_ampl, 90), 2 * down_p90), 2 * down_p90, max_tp)

    amp_labels.append([up_p10, up_p90, down_p10, down_p90])

labels_amplitude = np.array(amp_labels)

cut_len = len(labels_amplitude)
features = features.iloc[:cut_len].reset_index(drop=True)
df_clean = df_clean.iloc[:cut_len].reset_index(drop=True)
labels_direction = labels_direction[:cut_len]

assert len(features) == len(labels_amplitude) == len(labels_direction), "Ð Ð°ÑÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½ Ð¿Ð¾ÑÐ»Ðµ Amplitude!"
np.save(CFG.paths.train_labels_amplitude, labels_amplitude)
logging.info(f"âœ… Amplitude Ð¼ÐµÑ‚ÐºÐ¸: {len(labels_amplitude)}")

# 5ï¸âƒ£ HitOrder Ð¼ÐµÑ‚ÐºÐ¸
logging.info("Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ HitOrder Ð¼ÐµÑ‚Ð¾Ðº...")
shift = CFG.label_generation.hit_order_shift
window = CFG.label_generation.hit_order_window
sl_min = CFG.label_generation.hit_order_sl_min
sl_max = CFG.label_generation.hit_order_sl_max
rr_min = CFG.label_generation.hit_order_rr_min
rr_max = CFG.label_generation.hit_order_rr_max

hit_labels = []
for idx in range(len(df_clean) - shift - window + 1):
    win = df_clean.iloc[idx + shift: idx + shift + window]
    close = df_clean.iloc[idx]['close']

    sl_relative = np.random.uniform(sl_min, sl_max)
    sl_level = close * (1 - sl_relative)
    rr = np.random.uniform(rr_min, rr_max)
    tp_relative = sl_relative * rr
    tp_level = close * (1 + tp_relative)

    hit = 0
    for _, row in win.iterrows():
        if row['high'] >= tp_level:
            hit = 1
            break
        elif row['low'] <= sl_level:
            hit = 0
            break
    hit_labels.append([sl_relative, tp_relative, hit])

labels_hitorder = np.array(hit_labels)

final_len = len(labels_hitorder)
features = features.iloc[:final_len].reset_index(drop=True)
labels_direction = labels_direction[:final_len]
labels_amplitude = labels_amplitude[:final_len]

assert len(features) == len(labels_hitorder) == len(labels_amplitude) == len(labels_direction), "Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð°ÑÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½!"

np.save(CFG.paths.train_labels_hitorder, labels_hitorder)

# Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð°Ñ Ð·Ð°Ð¿Ð¸ÑÑŒ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
features.to_csv(CFG.paths.train_features_csv, index=False)
logging.info(f"âœ… Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸: {len(features)} ÑÑ‚Ñ€Ð¾Ðº")

logging.info("ðŸŽ¯ ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ ÑÑƒÐ¿ÐµÑ€ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð±Ð¾ÐµÐ²Ð¾Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½ Ð·Ð°Ð²ÐµÑ€ÑˆÑ‘Ð½!")
